{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HK PROTESTS: Visualising Chinese State Troll Tweets, Part 3 (Chinese Text)\n",
    "\n",
    "In Parts 3 and 4, I'll re-trace the steps in the previous two sections but for the Chinese tweets this time.\n",
    "\n",
    "I had problems plotting the frequency token distribution and tree map charts for Chinese characters, and decided to use Google Sheets instead to plot the key terms to speed up completion of this section. I'll update this notebook if I fix the font issue at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba, jieba.analyse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 300\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \"DE-LAYERING\" THE CHINESE TROLL TWEETS\n",
    "\n",
    "Steps below are broadly similar to Part 1, with some modifications for Chinese text, which has no word spacing, unlike English. I used the [jieba](https://github.com/fxsjy/jieba) word segmentation module for this projection. There are other options for Chinese NLP tasks, including modules from Stanford, Fudan etc. I would welcome feedback on whether adopting different Chinese NLP models/modules would significantly affect the outcomes here.\n",
    "\n",
    "## 1.1 DATA PRE-PROCESSING\n",
    "Download the original CSV files from [Twitter](https://blog.twitter.com/en_us/topics/company/2019/information_operations_directed_at_Hong_Kong.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (15,19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Reminder that the raw1/2 CSV files are NOT in this repo. Download directly from Twitter; link above\n",
    "raw1 = pd.read_csv('../data/china_082019_1_tweets_csv_hashed.csv')\n",
    "raw2 = pd.read_csv('../data/china_082019_2_tweets_csv_hashed.csv')\n",
    "raw = pd.concat([raw1, raw2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "raw = raw.drop(\n",
    "    columns=[\n",
    "        \"user_profile_url\",\n",
    "        \"tweet_client_name\",\n",
    "        \"in_reply_to_tweetid\",\n",
    "        \"in_reply_to_userid\",\n",
    "        \"quoted_tweet_tweetid\",\n",
    "        \"is_retweet\",\n",
    "        \"retweet_userid\",\n",
    "        \"retweet_tweetid\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"quote_count\",\n",
    "        \"reply_count\",\n",
    "        \"like_count\",\n",
    "        \"retweet_count\",\n",
    "        \"urls\",\n",
    "        \"user_mentions\",\n",
    "        \"poll_choices\",\n",
    "        \"hashtags\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting timings to HK time, and extracting year-month-day-hour cols\n",
    "raw['tweet_time'] = pd.to_datetime(raw['tweet_time'])\n",
    "raw['tweet_time'] = raw['tweet_time'].dt.tz_localize('GMT').dt.tz_convert('Hongkong')\n",
    "raw['tweet_year'] = raw['tweet_time'].dt.year\n",
    "raw['tweet_month'] = raw['tweet_time'].dt.month\n",
    "raw['tweet_day'] = raw['tweet_time'].dt.day\n",
    "raw['tweet_hour'] = raw['tweet_time'].dt.hour\n",
    "\n",
    "raw['account_creation_date'] = pd.to_datetime(raw['account_creation_date'], yearfirst=True)\n",
    "raw['year_of_account_creation'] = raw['account_creation_date'].dt.year\n",
    "raw['month_of_account_creation'] = raw['account_creation_date'].dt.month\n",
    "raw['day_of_account_creation'] = raw['account_creation_date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 DATA FILTERING + CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll focus only on tweets sent from 2017\n",
    "raw = raw[(raw[\"tweet_year\"] >= 2017)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out tweets which mention fugitive Chinese billionaire Guo Wengui, \n",
    "# and other irrelevant characters like US-based dissidents Yang Jianli, Guo Baosheng etc\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"éƒ­æ–‡è´µ\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"æ–‡è´µ\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"éƒ­æ–‡\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"æ¨å»ºåˆ©\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"éƒ­å®èƒœ\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"å®èƒœ\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"è€éƒ­\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"éƒ­ç‹—\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"éƒ­éª—å­\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"ä½™æ–‡ç”Ÿ\")].copy()\n",
    "raw = raw[~raw[\"tweet_text\"].str.contains(\"å´å°æ™–\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, I'll focus only on Chinese tweets. \n",
    "# In earlier drafts, I found that troll accounts with English language settings were sending out Chinese tweets too,\n",
    "# so provisions were made here to include those \n",
    "# Note the sub-categories for Twitter language settings for English and Chinese\n",
    "\n",
    "raw_ch = raw[\n",
    "    (raw[\"tweet_language\"] == \"zh\")\n",
    "    & (\n",
    "        (raw[\"account_language\"] == \"en\")\n",
    "        | (raw[\"account_language\"] == \"en-gb\")\n",
    "        | (raw[\"account_language\"] == \"zh-cn\")\n",
    "        | (raw[\"account_language\"] == \"zh-CN\")\n",
    "        | (raw[\"account_language\"] == \"zh-tw\")\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121962, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ch.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into two sub-sets, one for retweets and one for \"original\" tweets\n",
    "raw_ch_no_rt = raw_ch[~raw_ch[\"tweet_text\"].str.startswith(\"RT @\")].copy()\n",
    "\n",
    "raw_ch_rt = raw_ch[raw_ch[\"tweet_text\"].str.startswith(\"RT @\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106957, 20), (15005, 20))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surprisingly, the Chinese language tweets subset is smaller than the English one\n",
    "raw_ch_no_rt.shape, raw_ch_rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function to clean the tweet_text column and weed out non-Chinese text\n",
    "def clean_tweet_ch(text):\n",
    "    text = text.strip(\" \")\n",
    "    text = text.strip(r\"\\n\")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    filtered = re.compile(u'[^\\u4E00-\\u9FA5]') # non-Chinese unicode range\n",
    "    text = filtered.sub(r'', text) # remove all non-Chinese characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ch_no_rt['clean_tweet_text'] = raw_ch_no_rt['tweet_text'].map(lambda tweet: clean_tweet_ch(tweet))\n",
    "\n",
    "raw_ch_rt['clean_tweet_text'] = raw_ch_rt['tweet_text'].map(lambda tweet: clean_tweet_ch(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for a sample of the cleaned up \"original\" Chinese tweets\n",
    "#raw_ch_no_rt['clean_tweet_text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for a sample of the cleaned up Chinese retweets\n",
    "# raw_ch_rt['clean_tweet_text'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DIGGING THROUGH LAYER#1 - SPAM TWEETS GALORE BUT A HINT OF CONTENT TARGETTING THE PROTEST MOVEMENT\n",
    "\n",
    "Before plotting out the frequency distribution of key words, I settled on a brief list of Chinese stop words. They are not exhaustive by any means, and reflect words which I wanted to weed out following initial drafts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_stopwords = [\n",
    "    \"çš„\",\n",
    "    \"äº†\",\n",
    "    \"å’Œ\",\n",
    "    \"æ˜¯\",\n",
    "    \"å°±\",\n",
    "    \"éƒ½\",\n",
    "    \"è€Œ\",\n",
    "    \"åŠ\",\n",
    "    \"èˆ‡\",\n",
    "    \"è‘—\",\n",
    "    \"æˆ–\",\n",
    "    \"ä¸€å€‹\",\n",
    "    \"æ²’æœ‰\",\n",
    "    \"æˆ‘å€‘\",\n",
    "    \"ä½ å€‘\",\n",
    "    \"å¦³å€‘\",\n",
    "    \"ä»–å€‘\",\n",
    "    \"å¥¹å€‘\",\n",
    "    \"æ˜¯å¦\",\n",
    "    \"æ—¶é—´\",\n",
    "    \"æ•´ç‚¹\",\n",
    "    \"æŠ¥æ—¶\",\n",
    "    \"ç°åœ¨\",\n",
    "    \"æ—¥ç”µ\",\n",
    "    \"æœˆ\",\n",
    "    \"æ—¥\",\n",
    "    \"æ¡‚\",\n",
    "    \"æµ·\",\n",
    "    \"åœ¨\",\n",
    "    \"ç”µ\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /anaconda3/lib/python3.6/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /var/folders/6z/wrz4dxdx65585cc04rbtr1xh0000gn/T/jieba.cache\n",
      "Loading model cost 1.025320053100586 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "text = raw_ch_no_rt[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ä¸€ä¸ª äºº           1597\n",
       "è°· æ­Œ             918\n",
       "å¾® ä¿¡             704\n",
       "ä¸ çŸ¥é“            592\n",
       "è™ æ‰‘             578\n",
       "å®‰ å“             570\n",
       "ä¹‹ å®¶             562\n",
       "æ‰‘ è®¯             528\n",
       "è™ æ‰‘ è®¯           526\n",
       "å¤– åª’             522\n",
       "è®© ä½              516\n",
       "æ¯ä¸ª äºº            512\n",
       "å–œå‰§ äºº            503\n",
       "æ›´ å¤š             497\n",
       "ä¸–ç•Œ ä¸Š            470\n",
       "å°† äº             467\n",
       "ä¸€ç”Ÿ å¹³å®‰           462\n",
       "å¥½äºº ä¸€ç”Ÿ å¹³å®‰        462\n",
       "å¥½äºº ä¸€ç”Ÿ           462\n",
       "å¹³å®‰ å¥½äºº           460\n",
       "ä½  ä¼š             458\n",
       "ä¹Ÿ ä¼š             447\n",
       "è®© äºº             443\n",
       "å¦‚æœ ä½             441\n",
       "ä¼š æœ‰             439\n",
       "ä½  è‹¥             431\n",
       "æ¬¢ä¹ å–œå‰§ äºº         424\n",
       "æ¬¢ä¹ å–œå‰§           424\n",
       "å¤ª å¤š             412\n",
       "éª é¾™             398\n",
       "å¾® åš             388\n",
       "æ™’ æ—¥å…‰æµ´           386\n",
       "æ—¥å…‰æµ´ èˆ’æœ          385\n",
       "æ™’ æ—¥å…‰æµ´ èˆ’æœ        385\n",
       "å¥½äºº ä¸€ç”Ÿ å¹³å®‰ å¥½äºº     385\n",
       "å¹³å®‰ å¥½äºº ä¸€ç”Ÿ        385\n",
       "ä¸€ç”Ÿ å¹³å®‰ å¥½äºº ä¸€ç”Ÿ     385\n",
       "ä¸€ç”Ÿ å¹³å®‰ å¥½äºº        385\n",
       "å¹³å®‰ å¥½äºº ä¸€ç”Ÿ å¹³å®‰     385\n",
       "ä¹Ÿ ä¸             374\n",
       "ç»™ ä½              363\n",
       "å½“ ä½              358\n",
       "é­… æ—             357\n",
       "æˆ‘ ä¸             354\n",
       "è¯´ æˆ‘             352\n",
       "ä½  ä¸             348\n",
       "æ™’ æ—¥å…‰æµ´ èˆ’æœ æ™’      340\n",
       "èˆ’æœ æ™’ æ—¥å…‰æµ´        340\n",
       "èˆ’æœ æ™’            340\n",
       "æ—¥å…‰æµ´ èˆ’æœ æ™’        340\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVect for subset with \"original\" tweets\n",
    "# I raised the ngram_range to (2,4) and min_df to 10 after several rounds of trial and error. \n",
    "# Dial both down if you wish to see the count for single words\n",
    "\n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list1 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list1.sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tweets_ch01.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_ch_no_rt[raw_ch_no_rt[\"clean_tweet_text\"].str.contains('ä¸€ä¸ªäºº')].values\n",
    "# raw_ch_no_rt[raw_ch_no_rt[\"clean_tweet_text\"].str.contains('è°·æ­Œ')].values\n",
    "# raw_ch_no_rt[raw_ch_no_rt[\"clean_tweet_text\"].str.contains('æ—¥å…‰æµ´')].values\n",
    "# raw_ch_no_rt[raw_ch_no_rt[\"clean_tweet_text\"].str.contains('å¹³å®‰')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUICK TAKE: \n",
    "Like the English tweets, the lightly filtered Chinese tweets subset is extremely noisy as the chart above shows. The most frequently used words in \"original\" tweets did not throw up phrases targetted at the HK protest movement. The tweets are instead replete with spam content involving crime stories, US-China relations, and sunbathing, of all things.....Uncomment the cells above for a flavour of the spam content in the tweets.\n",
    "\n",
    "The retweets subset below, however, threw up early hints of the content aimed directly at the protest movement, with words like \"åé€ä¸­\" (anti-extradition bill), \"é¦™æ¸¯è­¦å¯Ÿ\" (Hong Kong police) and \"éŠè¡Œ\" (street rallies/protests) appearing in the top 50 list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ä¸¥é‡ æš´åŠ›çŠ¯ç½ª          246\n",
       "ä¸¥é‡ æš´åŠ›çŠ¯ç½ª æ¡ˆä»¶       206\n",
       "æš´åŠ›çŠ¯ç½ª æ¡ˆä»¶          206\n",
       "ä¾æ³• ä¾¦åŠ            204\n",
       "å…¬å®‰æœºå…³ ä¾æ³•          198\n",
       "å…¬å®‰æœºå…³ ä¾æ³• ä¾¦åŠ       196\n",
       "ä¸­å›½ äºº             178\n",
       "ä¸€èµ· ä¸¥é‡ æš´åŠ›çŠ¯ç½ª       165\n",
       "ä¸€èµ· ä¸¥é‡            165\n",
       "ä¸€èµ· ä¸¥é‡ æš´åŠ›çŠ¯ç½ª æ¡ˆä»¶    165\n",
       "ä¸­ ç¾              161\n",
       "é€ ä¸­              157\n",
       "ä¾¦åŠ ä¸€èµ·            151\n",
       "ä¾¦åŠ ä¸€èµ· ä¸¥é‡         151\n",
       "ä¾¦åŠ ä¸€èµ· ä¸¥é‡ æš´åŠ›çŠ¯ç½ª    151\n",
       "ä¸­ åœ‹              149\n",
       "ä¾æ³• ä¾¦åŠ ä¸€èµ·         148\n",
       "ä¾æ³• ä¾¦åŠ ä¸€èµ· ä¸¥é‡      148\n",
       "æ”¿æ²» åº‡æŠ¤            145\n",
       "å…¬å®‰æœºå…³ ä¾æ³• ä¾¦åŠ ä¸€èµ·    140\n",
       "é¦™æ¸¯ è­¦å¯Ÿ            140\n",
       "å é€ ä¸­            140\n",
       "å é€              140\n",
       "å· æ™®              136\n",
       "å å°              131\n",
       "ç ´ å£              121\n",
       "éŠ è¡Œ              120\n",
       "ç«‹æ³• æœƒ             120\n",
       "ä¸ çŸ¥é“             119\n",
       "é‡‡å– åˆ‘äº‹            118\n",
       "ç˜Ÿ é¬¼              117\n",
       "åˆ‘äº‹ å¼ºåˆ¶æªæ–½          114\n",
       "é‡‡å– åˆ‘äº‹ å¼ºåˆ¶æªæ–½       114\n",
       "èœè°± ä½œè€…            113\n",
       "ç¤¾ æœƒ              110\n",
       "æ’ è­¦              109\n",
       "çŠ¯ç½ª å«Œç–‘äºº           108\n",
       "é€ƒçŠ¯ æ¢             106\n",
       "æ¢ ä¾‹              106\n",
       "å çŠ¯ç½ª å«Œç–‘äºº         105\n",
       "å çŠ¯ç½ª             105\n",
       "é€ƒçŠ¯ æ¢ ä¾‹           104\n",
       "é˜¿ è´µ              102\n",
       "æ¨ å‹              101\n",
       "æ—  è¯­              100\n",
       "ä½  è¿˜               99\n",
       "è¿˜ èƒ½               98\n",
       "è¢« ä¾æ³•              98\n",
       "ç¾ åœ‹               95\n",
       "ä¹Ÿ ä¸               94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVect for subset with only retweets\n",
    "text = raw_ch_rt[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))\n",
    "    \n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list2 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list2.sort_values(ascending = False).head(50)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below for a flavour of the spam content in the retweet subset\n",
    "#raw_ch_rt[raw_ch_rt[\"clean_tweet_text\"].str.contains('ä¸­ç¾')].values\n",
    "#raw_ch_rt[raw_ch_rt[\"tweet_text\"].str.contains('ä¸­å›½')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"retweets_ch01.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DIGGING THROUGH LAYER#2 - TWEETS ON CHINESE DISSIDENTS/FUGITIVES, COMEDIES, AND US-CHINA RELATIONS\n",
    "\n",
    "Like in Part 1, I opted to filter directly for terms which would be more relevant to the analysis, given the amount of noise in the dataset.\n",
    "\n",
    "Following earlier trials, which I won't include here, I opted for the terms é¦™æ¸¯(Hong Kong), æ”¿åºœ(government), ä¸­å›½(China), é¡è‰²é©å‘½(Colour Revolution), å¤–åœ‹å‹¢åŠ›(Foreign Forces), and è­¦å¯Ÿ (police)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SIFTING THROUGH \"ORIGINAL\" CHINESE TROLL TWEETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_no_rt1 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"é¦™æ¸¯\")].copy()\n",
    "ch_no_rt2 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"æ”¿åºœ\")].copy()\n",
    "ch_no_rt3 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"ä¸­å›½\")].copy()\n",
    "ch_no_rt4 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"é¡è‰²é©å‘½\")].copy()\n",
    "ch_no_rt5 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"å¤–åœ‹å‹¢åŠ›\")].copy()\n",
    "ch_no_rt6 = raw_ch_no_rt[raw_ch_no_rt['tweet_text'].str.contains(\"è­¦å¯Ÿ\")].copy()\n",
    "\n",
    "hk_ch_no_rt = pd.concat([ch_no_rt1, ch_no_rt2, ch_no_rt3, ch_no_rt4, ch_no_rt5, ch_no_rt6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 412 unique users in this subset consisting of \"original\" tweets\n",
    "hk_ch_no_rt['user_screen_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ueV2dN3HOL24gOeDeNDZzDn0LU+68V9kby+jDR2pm4=     1085\n",
       "ingaibragimova1                                  834\n",
       "HKpoliticalnew                                   648\n",
       "charikamci                                       551\n",
       "mauricerowleyx                                   469\n",
       "zGKXuesfHo+nPb6rrSG61fpwFuGLKslqTK6weUoKWTI=     392\n",
       "KondratevFortu                                   160\n",
       "ctcc507                                          159\n",
       "bagaudinzhigj                                    126\n",
       "gdvcgsfsg                                        124\n",
       "Name: user_screen_name, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see some familiar troll accounts pop up again, particularly HKpoliticalnew and ctcc507\n",
    "# Both accounts were active in the English set in Part 1 as well\n",
    "hk_ch_no_rt['user_screen_name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@SuiBianXiaoGe æˆ–è®¸ä¸€è§‰é†’æ¥ï¼Œæˆ–è®¸æ˜å¤©ï¼Œæˆ–è®¸ä¸ä¹…çš„å°†æ¥ï¼Œé¦™æ¸¯äººå°±ä¼šæ˜ç™½ä¸è®ºæ˜¯è¿è¡Œã€Šé€ƒçŠ¯æ¡ä¾‹ã€‹è¿˜æ˜¯æš‚åœä¿®è®¢ã€Šé€ƒçŠ¯æ¡ä¾‹ã€‹éƒ½æ˜¯ä¸­å›½å¯¹é¦™æ¸¯äººæ°‘çš„çˆ±å’ŒåŒ…å®¹ï¼Œéƒ½æ˜¯ä¸ºäº†ç»´æŠ¤é¦™æ¸¯æ²»å®‰ç¨³å®šå’Œé¦™æ¸¯äººâ€œæ°‘ä¸»â€çš„è‰¯è‹¦ç”¨å¿ƒã€‚è€Œè¥¿æ–¹åååŠ¿åŠ›è¯•å›¾åœ¨é¦™æ¸¯æ¨åŠ¨çš„é¢œè‰²é©å‘½æœ€ç»ˆä¼šè¢«ä¸­å›½äººæ°‘é½å¿ƒååŠ›æ‰¼æ€åœ¨æ‘‡ç¯®ä¸­ã€‚',\n",
       "       'æ¸¯ç‰ˆå¾®ä¿¡æ”¯ä»˜å‡çº§ï¼â€œæ— ç°é‡‘â€ç”Ÿæ´»è¿˜è¿œå—ï¼Ÿ #å¾®ä¿¡ æ”¯ä»˜è¿‘æ—¥å®£å¸ƒï¼Œåœ¨é¦™æ¸¯æ¨å‡ºä¸€ç³»åˆ—å‡çº§æ”¯ä»˜åŠŸèƒ½ï¼Œæ ‡å¿—ç€é¦™æ¸¯åœ¨â€œæ— ç°é‡‘â€æ”¯ä»˜çš„è·¯ä¸Šåˆè¿ˆè¿›äº†ä¸€æ­¥ã€‚ é¦™æ¸¯æ¶ˆè´¹è€…é€šè¿‡å¾®ä¿¡æ‰«æäºŒç»´ç å¯å®Œæˆçº¿ä¸Šçº¿ä¸‹ã€ä¸åŒæ¶ˆè´¹åœºæ™¯çš„æ”¯ä»˜ï¼Œè€Œé¦™æ¸¯çš„å£«ã€æŠ¥åˆŠäº­ã€è¶…â€¦ https://t.co/mblIgvjTIK https://t.co/JC4uxCwltT',\n",
       "       '11æœˆ2æ—¥ä¸‹åˆæ¶ˆæ¯ï¼ŒåŒ11å‰å¤•ï¼Œæ”¯ä»˜å®åœ¨æµ·å¤–åœ¨çº¿æ”¯ä»˜é™†ç»­è½åœ°ã€‚è®¸å¤šå›½å®¶å’Œåœ°åŒºçš„æ”¯ä»˜æœºæ„æå‰å‡ ä¸ªæœˆï¼Œå°±å¼€å§‹è”åˆæ”¯ä»˜å®å‡çº§è‡ªå·±çš„åœ¨çº¿æ”¯ä»˜ç½‘ç»œï¼Œè²å¾‹å®¾å’Œé¦™æ¸¯çš„æœ¬åœ°é’±åŒ…ä»Šå¹´è¿˜å°†é¦–æ¬¡å‚ä¸â€œåŒ11â€ã€‚',\n",
       "       'èªè­˜å‚³æŸ“æ€§æ¥µå¼·çš„éº»ç–¹ï¼šç´ç´„ã€æ³°åœ‹ã€é¦™æ¸¯å„åœ°ç´›ç´›çˆ†ç™¼ï¼Œæœ‰å“ªäº›ç—‡ç‹€è©²å¦‚ä½•é é˜²ï¼Ÿ https://t.co/Tg9UhwAVa8',\n",
       "       '10æœˆ30æ—¥ï¼Œ #é¦™æ¸¯ç§‘æŠ€å¤§å­¦ å®£å¸ƒï¼Œè¯¥æ ¡æœºå™¨äººç ”ç©¶æ‰€çš„å¸ˆç”Ÿç ”å‘äº†é¦™æ¸¯é¦–éƒ¨æ‹¥æœ‰å¤šé¡¹åˆ›æ–°åŠŸèƒ½çš„ #æ— äººè½¦ã€‚ æ­¤å¤–ï¼Œä»–ä»¬è¿˜ç ”å‘äº†ä¸€ä¸ªç‰¹åˆ«è®¾è®¡çš„æ§åˆ¶å°ï¼Œèƒ½ç»Ÿä¸€æ§åˆ¶æ— äººè½¦çš„åŠ¨æ€åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç”µçº¿é©±åŠ¨çš„è½¬å‘ã€åŠ é€ŸåŠåˆ¶åŠ¨åŠŸèƒ½ã€‚ https://t.co/E0R2ryskkl https://t.co/WzK4rcR2Ee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This troll account was very active in the English subset as well\n",
    "hk_ch_no_rt[hk_ch_no_rt['user_screen_name']=='ctcc507']['tweet_text'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['é¦™æ¸¯å°†ä¿®ä¾‹ç¦æ­¢ç”µå­çƒŸï¼šè¿è€…æœ€é«˜ç½š5ä¸‡æ¸¯å…ƒåŠç›‘ç¦åŠå¹´ https://t.co/NlL2VYV28X',\n",
       "       'ç‰¹æ–¯æ‹‰åœ¨é¦™æ¸¯å»ºç«‹å……ç”µç«™ï¼šæœ‰50ä¸ªå……ç”µä½ ä¸ºäºšæ´²æœ€å¤§ https://t.co/fZCvguZaSy',\n",
       "       'ä¸­å›½è”é€šå®£å¸ƒä¸é¦™æ¸¯ã€æ¾³é—¨ç”µè®¯åˆä½œï¼šç²¾å“ç½‘å»¶è¿Ÿ1æ¯«ç§’ https://t.co/NKahtMVhUM',\n",
       "       'æ¶ˆæ¯ç§°é¦™æ¸¯å°†å‘6å®¶å…¬å¸å‘æ”¾æ•°å­—é“¶è¡Œç‰Œç…§ è…¾è®¯å°ç±³ç­‰åœ¨å†… https://t.co/AlxLAnTYM0',\n",
       "       'é¦™æ¸¯ä¸­æ–‡å¤§å­¦å¼€è®¾é¦–ä¸ªäººå·¥æ™ºèƒ½å­¦ä½è¯¾ç¨‹ https://t.co/xeloTj0bGX'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The key words filter don't always accurately filter for content targetting the protest movement\n",
    "# This user's tweets seemed mostly irrelevant\n",
    "hk_ch_no_rt[hk_ch_no_rt['user_screen_name']=='ingaibragimova1']['tweet_text'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['åƒåé»‘è¡£äººåœå µç«‹æœƒï¼Œç•¶ä¸­ä¸ä¹é‡è£ä¸Šé™£çš„äººï¼Œè­¦æ–¹ä¸€å®šè¦åš´é˜²ï¼Œå¤§å®¶å°å¿ƒï¼ğŸ‘ğŸ’ª\\n\\n#é¦™æ¸¯ #å¤§å°ˆå­¸ç•Œ #å‡ç´šè¡Œå‹• #åŒ…åœç«‹æœƒ #é‡è£ä¸Šé™£ #è­¦å¯Ÿ \\nåŸåœ–ï¼šæ˜Ÿå³¶æ—¥å ± https://t.co/DIoiFWWkBo',\n",
       "       'ç«‹æœƒç¶“æš´äº‚ä¸€å½¹ï¼Œå¹¾è¿‘æ·ªç‚ºå»¢å¢Ÿã€‚\\n\\næ“šã€Šæ˜Ÿå³¶æ—¥å ±ã€‹å ±é“ï¼Œæ˜¨æ—¥ï¼Œè­¦æ–¹çµ„ç¹”ç½ªæ¡ˆåŠä¸‰åˆæœƒèª¿æŸ¥ç§‘åˆ°ç«‹æœƒè’è­‰èª¿æŸ¥ï¼Œå·²æŒæ¡ååæš´å¾’è³‡æ–™ï¼Œä»–å€‘äº‹æ¶‰æš´åŠ›è¡æ“ŠåŒ…åœç­‰äº‹ï¼Œä¸¦æ–¼æ—¥å…§æ‹‰äººã€‚æœ¬å ±æ–¼æ—©ä¸Šäº¦æ›¾å ±é“ï¼ŒåŸ·æ³•è€…æˆ–æœƒæ‹˜æ•èµ·è­¦åº•ä½œæ¬ºå‡Œè€…ã€‚\\n\\n#é¦™æ¸¯ #ç«‹æ³•æœƒå¤§æ¨“ #æ˜Ÿå³¶æ—¥å ± #æš´å¾’ #æ—¥å…§æ‹‰äºº https://t.co/m0KCaYLAkx',\n",
       "       'ä½œç‚ºæ•™è‚²å·¥ä½œè€…ç†æ‡‰ã€Œå‚³é“ã€æˆæ¥­ã€è§£æƒ‘ã€ï¼Œå°æ–¼ä¿®è¨‚ã€Šé€ƒçŠ¯æ¢ä¾‹ã€‹é€™å€‹é—œä¿‚é¦™æ¸¯æ³•æ²»çš„é‡å¤§è­°é¡Œï¼Œæ›´æ‡‰è©²å°å­¸ç”Ÿè² èµ·ã€Œè¬›æ¸…æ¥šã€è¬›æ˜ç™½ã€çš„è²¬ä»»ã€‚\\nhttps://t.co/XgbK2aSG6sæ¸¯äººåšè©•/45389/åä¿®ä¾‹èª¤å°å¹´è¼•äººèµ°ä¸Šæš´åŠ›è¡æ“Šé‚ªè·¯?fbclid=IwAR0tp45O3W7PdltdwfWaFlAvkweUfMEiImn8nyrF61vQVvLQwu3p6PoPZk8#selected',\n",
       "       '#è¥¿ç­ç‰™ å˜…è­¦å¯Ÿå°ä»˜å·´æ–¯å…‹åˆ†é›¢ä»½å­ã€‚æ£æ£æ‰“ä¸‹å»ï¼Œçµ•å””æ‰‹è»Ÿï¼Œå®Œå…¨åˆæ³•ï¼Œçµ•ç„¡æ‰‹å°¾ã€‚\\nå°æ¯”ä¹‹ä¸‹ï¼Œç³»å””ç³»è¦ºå¾— #é¦™æ¸¯è­¦å¯Ÿ ç¢ºå¯¦å·²ç¶“å¾ˆæº«æŸ”äº†ï¼Ÿ https://t.co/rhHIXiPUn8',\n",
       "       '#é¦™æ¸¯ åå°æ´¾ä¸€å†æ•£å¸ƒå¤±å¯¦è³‡è¨ŠæŠ¹é»‘ä¿®ä¾‹ã€èª¤å°å¸‚æ°‘ï¼Œæ›´ä¸æ–·é€ è¬ ç…½å‹•æƒ…ç·’ï¼Œä¼åœ–ä»¥ç¶²æ°‘å£“åŠ›æ¯è‘›æ”¯æŒä¿®ä¾‹ç”šè‡³åªæ˜¯æ²‰é»˜çš„å•†æˆ¶ã€‚\\næ”¿åºœæ±ºå®šåœæ­¢ä¿®ä¾‹å·¥ä½œå¾Œï¼Œåå°æ´¾åˆç¹¼çºŒæ’­è¬ ï¼Œç¨±æ›é ˜æ™ºèƒ½èº«ä»½è­‰æœƒã€Œå¤±å»é¸æ°‘è³‡æ ¼ã€ï¼Œä¼åœ–æ’•è£‚å¸‚æ°‘å°ç¤¾æœƒä¸åŒç•Œåˆ¥ã€åœ˜é«”ã€çµ„ç¹”çš„ä¿¡ä»»ã€‚ https://t.co/9B3xCI9MWv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This troll account was very active in the English subset as well\n",
    "hk_ch_no_rt[hk_ch_no_rt['user_screen_name']=='HKpoliticalnew']['tweet_text'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "æ¢ ä¾‹       229\n",
       "ç‰¹ å€       218\n",
       "ä¸­å›½ äºº      212\n",
       "æ¸¯ ç¨       197\n",
       "å å°       194\n",
       "ç«‹æ³• æœƒ      189\n",
       "é¦™æ¸¯ è­¦å¯Ÿ     183\n",
       "ç¾ åœ‹       180\n",
       "å€ æ”¿åºœ      177\n",
       "ç‰¹ å€ æ”¿åºœ    172\n",
       "é€ƒçŠ¯ æ¢ ä¾‹    170\n",
       "é€ƒçŠ¯ æ¢      170\n",
       "ä¸­å›½ é©»      164\n",
       "ç¤¾ æœƒ       162\n",
       "ä¸­ ç¾       158\n",
       "å¯¹ ä¸­å›½      147\n",
       "å å° æ´¾     140\n",
       "å° æ´¾       140\n",
       "ä¸­ åœ‹       138\n",
       "æ°‘æ— é»¨      135\n",
       "æ— é„­       129\n",
       "é¦™æ¸¯ ç‰¹      125\n",
       "ç¸½ éƒ¨       120\n",
       "ä¿® ä¾‹       119\n",
       "è¡Œ å‹•       117\n",
       "é¦™æ¸¯ ç‰¹ å€    117\n",
       "ä¸“é¡¹ è¡ŒåŠ¨     113\n",
       "å‹¢ åŠ›       112\n",
       "å­¸ ç”Ÿ       112\n",
       "ç™¼ å±•       110\n",
       "æœƒ è­°       109\n",
       "ä¸ ä¸­å›½      108\n",
       "é¦™æ¸¯ äºº      108\n",
       "ä¸­å›½ æ³•å¾‹     107\n",
       "è¨˜ è€…       106\n",
       "å¤– åœ‹       106\n",
       "ä¿® è¨‚       105\n",
       "é€ƒçŠ¯ æ¡ä¾‹     103\n",
       "è­° å“¡       100\n",
       "æ’ è­¦        99\n",
       "ä¸­å›½ æ¸¸å®¢      98\n",
       "åœ‹ å®¶        97\n",
       "å¤§ å­¸        97\n",
       "ä¸¤ å›½        94\n",
       "é„­ å¨¥        93\n",
       "æ— é„­ å¨¥      93\n",
       "é¦™æ¸¯ æ°‘æ—      93\n",
       "ä¸€ å€‹        91\n",
       "å…§ åœ°        90\n",
       "å¤– åª’        90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sticking to the same min_df and ngram_range values\n",
    "\n",
    "text = hk_ch_no_rt[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))\n",
    "    \n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list3 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list3.sort_values(ascending = False).head(50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tweets_ch02.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hk_ch_no_rt[hk_ch_no_rt[\"tweet_text\"].str.contains('åå°æ´¾')].values\n",
    "# hk_ch_no_rt[hk_ch_no_rt[\"tweet_text\"].str.contains('é¦™æ¸¯è­¦å¯Ÿ')].values\n",
    "# hk_ch_no_rt[hk_ch_no_rt[\"tweet_text\"].str.contains('æ¸¯ç¨')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUICK TAKE: \n",
    "\n",
    "The most active trolls, as we can see here and in Part 1, are posting content in English and Chinese, the two primary languages at play here. HKpoliticalnew and ctcc507, for instances, are tweeting in both languages.\n",
    "\n",
    "The direct filtering also gives us a better sense of the messages that the trolls were trying to push. A sample:\n",
    "\n",
    "- @charikamci, tweeting at 2018-08-19 00:26:00+08:00: 'é¦™æ¸¯å›æ­¸è‡³ä»Šåå°æ´¾ä¸æ™‚èˆˆé¢¨ä½œæµªå¹´çˆ†ç™¼æ—¥é•æ³•ä½”ä¸­åå°æ´¾å€’æ‰“ä¸€è€™å°‡è²¬ä»»æ¨åˆ°ç‰¹å€æ”¿åºœå’Œä¸­å¤®èº«ä¸Šå¤§å…¬å ±ç²å¾—çš„æœ€æ–°æ©Ÿå¯†æ–‡ä»¶é¡¯ç¤ºä½”ä¸­å…¶å¯¦æ˜¯äº‚æ¸¯æ´¾èˆ‡å¢ƒå¤–åè¯å‹¢åŠ›ç²¾å¿ƒç­–å‹•çš„ä¸€å ´é¡è‰²é©å‘½æ—¨åœ¨åˆ©ç”¨å¹´è¼•äººå¦„åœ–ä¸€å¤œè®Šå¤©']\n",
    "\n",
    "- @Resilceale; tweeting at 2019-07-09 12:17:00+08:00: ä»¥ã€Œåä¿®ä¾‹ã€ç‚ºå€Ÿå£ï¼Œä»¥å­¸ç”Ÿç‚ºæ£‹å­ï¼Œä»¥æ‰“ç ¸ç‚ºæ‰‹æ®µï¼Œä»¥åˆ†åŒ–ç‚ºç›®çš„ï¼Œé¦™æ¸¯åå°æ´¾ä¸æƒœé‡é‡‘æ‹›å‹Ÿï¼Œå¹•å¾ŒæŒ‡ä½¿å­¸ç”Ÿ ã€Œæ²–æ“Šç«‹æ³•æœƒã€ï¼Œè®“ã€Œæ±æ–¹æ˜ç ã€å˜…å¤©ç©ºå¸ƒæ»¿é™°éœ¾ï¼Œæ¸¯æ°‘æ‡‰æ“¦äº®æ…§çœ¼ï¼\"\n",
    "\n",
    "- @qujianming1; tweeting at 2019-07-02 10:14:00+08:00: 'é¦™æ¸¯ä¸ƒä¸€æ¸¸è¡Œæ°‘é˜µæœˆæ—¥åå¯¹æ´¾å®£æ‰¬æš´åŠ›å†²å‡»ç«‹æ³•ä¼šçš„ä¸¾åŠ¨æ˜¯å¯¹é¦™æ¸¯ç™¾å¹´æ³•æ²»ç²¾ç¥çš„è·µè¸å°†å’Œå¹³æ¸¸è¡Œæ¼”å˜æˆé¢œè‰²é©å‘½ä»¤äººæ„¤æ…¨æ­¤æ—¶åˆ»é¦™æ¸¯å¸‚æ°‘åº”è¯¥ä¿æŒå…‹åˆ¶å†·é™ç”¨ç†æ€§å’Œå¹³çš„æ–¹å¼è¡¨è¾¾æ„è§æºæ‰‹é¦™æ¸¯è­¦å¯Ÿå…±åŒç»´æŠ¤ç¤¾ä¼šç¨³å®šç¤¾ä¼šå„ç•Œæ›´åº”å†·é™ç†æ€§å…±åŒä¿ƒè¿›é¦™æ¸¯æ³•æ²»è¿›æ­¥'\n",
    "\n",
    "- @maksmkas6g; tweeting at 2019-07-04 17:11:00+08:00: '@bindarsou æ‰“æ‰è¿™å¸®æš´å¾’çš„åš£å¼ ï¼Œé¦™æ¸¯è­¦å¯ŸåŠ æ²¹'\n",
    "\n",
    "- @Resilceale, tweeting at 2019-07-09 12:15:00+08:00: 'é¦™æ¸¯å˜…ã€Œæ¸¯ç¨ã€åˆ†å­ï¼Œç‚ºäº†é”åˆ°ä¸å¯å‘Šäººä¹‹ç›®çš„ï¼Œç…½å‹•ä¸æ˜çœŸç›¸å˜…é’å¹´äººåƒèˆ‡æ¸¸è¡Œï¼Œç”šè‡³é€²è¡Œæ‰€è¬‚å˜…æ‰“ç ¸æ¶é•æ³•è¡Œç‚ºå‘æ”¿åºœæ–½å£“ã€‚ä»²ç³»é†’é†’å§ï¼Œå°‘å¹²é»è ¢äº‹ï¼Œå¤šé•·é»å¿ƒçœ¼ï¼ä¸–ç•Œä¸Šå†‡é‚Šå€‹åœ‹å®¶å…è¨±å‘¢ç¨®çŒ–ç‹‚è¡Œå¾‘ç››è¡Œå˜…ï¼Œå””ç³»å””æ‰“ï¼Œè‚¯å®šè¦æ‰“æ‰å˜…ï¼è€Œä¸”è¦é‡æ‰“ï¼\n",
    "\n",
    "Uncomment the lines above to see a fuller set of the tweets. The content in itself is not surprising - essentially backing the Hong Kong police and blaming secessionist groups and \"hostile foreign forces\" for trying to forment a colour revolution.\n",
    "\n",
    "A detailed content analysis, however, is outside the scope of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 SIFTING THROUGH CHINESE TROLL RETWEETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_rt1 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"é¦™æ¸¯\")].copy()\n",
    "ch_rt2 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"æ”¿åºœ\")].copy()\n",
    "ch_rt3 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"ä¸­å›½\")].copy()\n",
    "ch_rt4 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"é¡è‰²é©å‘½\")].copy()\n",
    "ch_rt5 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"å¤–åœ‹å‹¢åŠ›\")].copy()\n",
    "ch_rt6 = raw_ch_rt[raw_ch_rt['tweet_text'].str.contains(\"è­¦å¯Ÿ\")].copy()\n",
    "\n",
    "hk_ch_rt = pd.concat([ch_rt1, ch_rt2, ch_rt3, ch_rt4, ch_rt5, ch_rt6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_ch_rt['user_screen_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FWE41OnopBB5h3unPH3s3XBA3t3zEuROlhnEue2H8cE=    369\n",
       "benjaminkudla39                                 110\n",
       "HKpoliticalnew                                   62\n",
       "GirgRKG36vs7eBx81goMAn6AlVfUp0RjKLwCCdd7aU=      60\n",
       "ardansuweb                                       60\n",
       "randxr89c                                        44\n",
       "w9pbfQRUXBcO810z7Q9I5TbWnGdbZaBB3Gvh6KxT6Y=      39\n",
       "fMPA8G2z8yjkrEMdZkNSnRraECis1zX6tv2N7NcF7aY=     34\n",
       "2l1eDka0eiClBUYoDXlwYaKcUaeelnz44aDM9OJRM=       31\n",
       "Melissa64269411                                  28\n",
       "Name: user_screen_name, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_ch_rt['user_screen_name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @simsoer: æ›¾ç¶“äºæ´²æœ€å®‰å…¨åŸå¸‚å˜…ç· é€ è€…-é¦™æ¸¯è­¦å¯Ÿï¼Œç‚ºäº†æœ€å°å˜…å‚·å®³ä¿æŒäº†æœ€å¤§å˜…å…‹åˆ¶ã€‚ åš´æ­£è²æ˜â€”â€”å¼·åŠ›æ”¯æŒé¦™æ¸¯è­¦å¯Ÿå˜…åŸ·æ³•è¡Œç‚ºï¼Œå¼·çƒˆè­´è²¬é¦™æ¸¯åä¿®ä¾‹æš´å¾’æš´åŠ›å˜…è¡Œç‚ºï¼Œæ„¿é¦™æ¸¯é‡æ­¸ç©©å®šï¼Œé½Šå¿ƒå»ºè¨­ç²µæ¸¯æ¾³ç£å€ #HK #HongKongProtest \\nhttps://t.co/â€¦',\n",
       "       'RT @CNS1952: ä½³å£«å¾—é¦™æ¸¯2019å¹´æ˜¥å­£æ‹å–ä¼šå°†äº24æ—¥åœ¨é¦™æ¸¯ä¼šå±•ä¸­å¿ƒå¼€æ§Œã€‚ä¸ºæœŸä¸€å‘¨çš„æ˜¥æ‹å°†å‘ˆçŒ®ä¸­å›½ä¹¦ç”»ã€ä¸­å›½ç“·å™¨åŠè‰ºæœ¯å“ã€äºšæ´²äºŒåä¸–çºªåŠå½“ä»£è‰ºæœ¯ã€ç å®åè¡¨ç­‰å¤šä¸ªä¸“åœºï¼Œæ‹å“æ¨ªè·¨å¤ä»£è‡³å½“ä»£çš„ä¸œè¥¿æ–¹è‰ºæœ¯ã€‚ https://t.co/BtQYX2Egyr',\n",
       "       'RT @CNS1952: 7æœˆ8æ—¥ï¼Œç”±é¦™æ¸¯è´¸æ˜“å‘å±•å±€ä¸»åŠçš„ç¬¬26å±Šé¦™æ¸¯æ—¶è£…èŠ‚æ˜¥å¤ç³»åˆ—å‡æ¹¾ä»”é¦™æ¸¯ä¼šè®®å±•è§ˆä¸­å¿ƒä¸¾è¡Œã€‚ä¸€è¿å››æ—¥çš„å±•è§ˆä»¥Oriental Feverä¸ºå¸ƒå±•ä¸»é¢˜ï¼Œå¸å¼•æ¥è‡ª12ä¸ªå›½å®¶åŠåœ°åŒºçº¦ä¸€åƒå®¶å‚å±•å•†å‚ä¸ã€‚æ¥çœ‹çœ‹å¼€å¹•æ—¶è£…å·¡ç¤¼è¡¨æ¼”å§ï¼ https://t.co/Et045pâ€¦',\n",
       "       'RT @CNS1952: 5æœˆ22æ—¥ï¼Œä¸­å›½ä¸€æ”¯æ°‘é—´å¥³å­ç™»å±±é˜ŸæˆåŠŸç™»é¡¶ç ç©†æœ—ç›å³°ã€‚åˆ†åˆ«æ¥è‡ªæ–°ç–†ã€é¦™æ¸¯ã€æ²³å—çš„é©¬ä¸½å¨…å§†ã€æ›¾ç‡•çº¢ã€å­™å®ç›¸ç»§ç™»é¡¶ã€‚ä»4æœˆ8æ—¥å‡ºå‘è‡³ä»Šï¼Œå¥¹ä»¬å†ç»40å¤šå¤©åˆ°è¾¾ä¸–ç•Œä¹‹å·…ã€‚ç›®å‰ï¼Œå¥³å­ç™»å±±é˜Ÿçš„å…¨éƒ¨æˆå‘˜æ­£åœ¨å®‰å…¨ä¸‹æ’¤é€”ä¸­ã€‚#ä¸­å›½æ•…äº‹ https://t.co/q9JTâ€¦',\n",
       "       'RT @CNS1952: é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒºä¸€äº›æç«¯æ¿€è¿›åˆ†å­1æ—¥ä»¥æä¸ºæš´åŠ›çš„æ–¹å¼å†²å‡»ç«‹æ³•ä¼šå¤§æ¥¼ï¼Œè‚†æ„æŸåç«‹æ³•ä¼šè®¾æ–½ï¼Œæµ·å¤–ä¸“å®¶å­¦è€…å¯¹æ­¤çº·çº·å‘å£°è°´è´£ï¼Œè®¤ä¸ºè¿™æ˜¯è·µè¸æ³•æ²»ã€å±å®³ç¤¾ä¼šç§©åºçš„ä¸¥é‡è¿æ³•è¡Œä¸ºï¼Œå¹¶å‘¼åå¤–å›½åŠ¿åŠ›åœæ­¢æ’æ‰‹é¦™æ¸¯äº‹åŠ¡å’Œä¸­å›½å†…æ”¿ã€‚https://t.co/NDVO6CxZZlâ€¦'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's still noise in these filtered tweets, evidenced by the tweets on a fashion festival and art auction\n",
    "hk_ch_rt[hk_ch_rt['user_screen_name']=='ardansuweb']['tweet_text'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @aptib08e7: #é¦™æ¸¯ #hongkong ç‡åˆ°æš´åŠ›è¡Œç‚ºå’Œæ´»å‹•ï¼Œé¦–å…ˆæˆ‘èªç‚ºä½œç‚ºä¸€å€‹é¦™æ¸¯äººï¼Œå°±æ‡‰è©²å¾è‡ªå·±åšèµ·ï¼Œå¾ä¸€å€‹ç¶­è­·é¦™æ¸¯ç¤¾æœƒå¤§å±€ç©©å®šå˜…è§’åº¦å‡ºç™¼ï¼Œè‡ªè¦ºæŠµè§¸å‘¢ç¨®æš´åŠ›å˜…æ´»å‹•ï¼Œä¸¦å¤§è²å˜…å‘¼åç¤¾æœƒå„ç•Œç›¡å¿«å†·éœè½åšŸï¼Œå””å¥½åƒèˆ‡è«¸å¦‚æ­¤é¡å˜…æ´»å‹•ï¼Œé¦™æ¸¯éœ€è¦å˜…ç³»å’Œå¹³ã€ç™¼å±•ã€ç¹æ¦®ï¼Œè€Œå””ç³»â€¦',\n",
       "       'RT @simsoer: æ›¾ç¶“äºæ´²æœ€å®‰å…¨åŸå¸‚å˜…ç· é€ è€…-é¦™æ¸¯è­¦å¯Ÿï¼Œç‚ºäº†æœ€å°å˜…å‚·å®³ä¿æŒäº†æœ€å¤§å˜…å…‹åˆ¶ã€‚ åš´æ­£è²æ˜â€”â€”å¼·åŠ›æ”¯æŒé¦™æ¸¯è­¦å¯Ÿå˜…åŸ·æ³•è¡Œç‚ºï¼Œå¼·çƒˆè­´è²¬é¦™æ¸¯åä¿®ä¾‹æš´å¾’æš´åŠ›å˜…è¡Œç‚ºï¼Œæ„¿é¦™æ¸¯é‡æ­¸ç©©å®šï¼Œé½Šå¿ƒå»ºè¨­ç²µæ¸¯æ¾³ç£å€ #HK #HongKongProtest \\nhttps://t.co/â€¦',\n",
       "       'RT @anafedinzp: #HongKong #HK çœ¾æ‰€å‘¨çŸ¥ï¼Œé¦™æ¸¯è­¦éšŠä½œç‚ºç¶­è­·é¦™æ¸¯å®‰å®šå˜…å®ˆè­·è€…å¾€å¾€æ‰¿æ“”è‘—æ¯”å…¶ä»–è·æ¥­æ›´å¤šå˜…ç¤¾æœƒè²¬ä»»å’Œå£“åŠ›ã€‚é¢å°è¿‘æœŸå‘¢ä¸€ç³»åˆ—è¡çªäº‹ä»¶ï¼Œé¦™æ¸¯è­¦æ–¹é¢å°å·²æˆé¨·äº‚å˜…æš´åŠ›è¡Œå¾‘è¢«è¿«æ¡å–å’—å¿…è¦å˜…è™•ç½®æ‰‹æ®µï¼Œæ—¢ä¿æŒå’—å‰‹åˆ¶ï¼Œæ…‹åº¦åˆå …æ±ºã€‚æˆ‘å“‹èªç‚ºï¼Œé¦™æ¸¯è­¦æ–¹è¡¨ç¾å‡ºå˜…â€¦',\n",
       "       'RT @CNS1952: åŸå®š28æ—¥è¿›è¡Œæ‹å–çš„æ¸…ä»£ç”»å®¶ä»»ä¼¯å¹´ç”»ä½œã€Šæ¾¹é»„æ¨æŸ³å¸¦æ –é¸­ã€‹äº26æ—¥é¢„å±•æ—¶è¢«ä¸€åå°ç«¥æ’•æ¯ã€‚ä½³å£«å¾—é¦™æ¸¯æ–¹é¢ç§°å·²é€šçŸ¥å§”æ‰˜æ–¹ï¼Œå¹¶æ’¤æ‹è¯¥ä½œå“ã€‚è¢«æ¯çš„ç”»ä½œä¸ºåˆ›ä½œäº1889å¹´çš„ã€ŠèŠ±é¸Ÿå››å±ã€‹ä¸­çš„ä¸€å¹…ã€‚æ•´ç»„ä½œå“ä¼°ä»·ä¸º150ä¸‡è‡³250ä¸‡æ¸¯å…ƒï¼ˆçº¦åˆ19è‡³31ä¸‡ç¾å…ƒï¼‰ã€‚httpâ€¦',\n",
       "       'RT @CNS1952: 2019é¦™æ¸¯ç©å…·èŠ‚16æ—¥åœ¨é¦™æ¸¯ä¼šå±•ä¸­å¿ƒç»§ç»­ä¸¾è¡Œã€‚æœ¬å±Šç©å…·èŠ‚å¸å¼•ä¼—å¤šç©å…·è¿·èœ‚æ‹¥å…¥åœºï¼Œé™¤äº†å„¿ç«¥ä»¥å¤–ï¼Œäº¦æœ‰ä¼—å¤šæˆå¹´ç©å…·è¿·å‰æ¥å‚è§‚ã€é€‰è´­æ½®æµç©å…·å’Œæ€€æ—§ç©å…·ã€‚ https://t.co/qnUBRQPX58'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hk_ch_rt[hk_ch_rt['user_screen_name']=='randxr89c']['tweet_text'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "é¦™æ¸¯ è­¦å¯Ÿ       285\n",
       "é€ ä¸­         207\n",
       "æ’ è­¦         205\n",
       "å å°         199\n",
       "ä¸­å›½ äºº        189\n",
       "å é€         181\n",
       "å é€ ä¸­       181\n",
       "è¡Œ å‹•         159\n",
       "ç¤¾ æœƒ         156\n",
       "é€ƒçŠ¯ æ¢        137\n",
       "æ¢ ä¾‹         137\n",
       "é€ƒçŠ¯ æ¢ ä¾‹      135\n",
       "ç ´ å£         131\n",
       "è¡Œ ç‚º         127\n",
       "éŠ è¡Œ         126\n",
       "æˆ‘ å“‹         126\n",
       "é¦™æ¸¯ æ’        117\n",
       "å° æ´¾         117\n",
       "å å° æ´¾       117\n",
       "ç«‹æ³• æœƒ        115\n",
       "ä¸­ é¦™æ¸¯        115\n",
       "é€ ä¸­ é¦™æ¸¯      115\n",
       "åŸ· æ³•         112\n",
       "ä¿® ä¾‹         110\n",
       "æš´ å‹•         107\n",
       "è­¦å¯Ÿ å˜…        106\n",
       "å­¸ ç”Ÿ         102\n",
       "åš´ æ­£         101\n",
       "ç©© å®š          96\n",
       "è­¦ éšŠ          95\n",
       "è­´ è²¬          92\n",
       "å é€ ä¸­ é¦™æ¸¯     89\n",
       "ä¸­ ç¾          86\n",
       "å‹¢ åŠ›          83\n",
       "è­¦ è¡Œ          83\n",
       "è­¦ è¡Œ å‹•        83\n",
       "æ’ è­¦ è¡Œ å‹•      83\n",
       "æ’ è­¦ è¡Œ        83\n",
       "åä¿® ä¾‹         82\n",
       "æ’ è­¦ éšŠ        82\n",
       "é¦™æ¸¯ æ’ è­¦ è¡Œ     81\n",
       "ä½  æˆ‘          81\n",
       "é¦™æ¸¯ æ’ è­¦       81\n",
       "éšŠ ä½  æˆ‘ åŒè¡Œ     80\n",
       "æ’ è­¦ éšŠ ä½       80\n",
       "è­¦ éšŠ ä½         80\n",
       "è­¦ éšŠ ä½  æˆ‘      80\n",
       "éšŠ ä½           80\n",
       "ä½  æˆ‘ åŒè¡Œ       80\n",
       "æˆ‘ åŒè¡Œ         80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = hk_ch_rt[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))\n",
    "    \n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list4 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list4.sort_values(ascending = False).head(50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"retweets_ch02.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hk_ch_rt[hk_ch_rt[\"tweet_text\"].str.contains('åå°æ´¾')].values\n",
    "# hk_ch_rt[hk_ch_rt[\"tweet_text\"].str.contains('é¦™æ¸¯è­¦å¯Ÿ')].values\n",
    "# hk_ch_rt[hk_ch_rt[\"tweet_text\"].str.contains('æ¸¯ç¨')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retweets push a similar narrative - praising the police for taking action and condemning the violent protests. Uncomment the cell above for a fuller look. A sample: \n",
    "\n",
    "'RT @bindarsou: é¦™æ¸¯è­¦å¯ŸçœŸæ­£å˜…æ­£ç¾©ä½¿è€…åå°æ´¾æ±¡è”‘æ”»å‡»é¦™æ¸¯è­¦å¯Ÿå˜…ç›®çš„ä¿‚ç‚ºå’—æ“¾äº‚é¦™æ¸¯å˜…ç¤¾æœƒç©©å®šç›¸ä¿¡å»£å¤§å…·æœ‰æ­£ç¾©æ„Ÿå˜…å¸‚æ°‘åŒå­¸ç”Ÿå®šèƒ½ç‡æ¸…äº‹å¯¦ä¸å†è¢«åå°æ´¾åˆ¶é€ å˜…å‡è±¡è¿·æƒ‘è­´è²¬åˆ©ç”¨å­¸ç”Ÿé€²è¡Œæš´åŠ›å˜…é‚‹é¢è¡Œç‚ºé¦™æ¸¯è­¦å¯Ÿæ’æ¸¯è­¦åæš´åŠ›éŠè¡Œ'\n",
    "\n",
    "'RT @simsoer: æ›¾ç¶“äºæ´²æœ€å®‰å…¨åŸå¸‚å˜…ç· é€ è€…é¦™æ¸¯è­¦å¯Ÿç‚ºäº†æœ€å°å˜…å‚·å®³ä¿æŒäº†æœ€å¤§å˜…å…‹åˆ¶åš´æ­£è²æ˜å¼·åŠ›æ”¯æŒé¦™æ¸¯è­¦å¯Ÿå˜…åŸ·æ³•è¡Œç‚ºå¼·çƒˆè­´è²¬é¦™æ¸¯åä¿®ä¾‹æš´å¾’æš´åŠ›å˜…è¡Œç‚ºæ„¿é¦™æ¸¯é‡æ­¸ç©©å®šé½Šå¿ƒå»ºè¨­ç²µæ¸¯æ¾³ç£å€'\n",
    "\n",
    "'RT @GolloglyAlysha: #é¦™æ¸¯ #é€ƒçŠ¯æ¢ä¾‹ çœ‹çœ‹ç¾åœ‹æ˜¯æ€éº¼åŸ¹é¤Šæ¸¯ç¨å‹¢åŠ›çš„é€™äº›æ‰€è¬‚çš„é’å¹´ç²¾è‹±ç„¡éæ˜¯ç¾åœ‹äººçš„æ£‹å­ç¦æ¸¯äº‚æ¸¯çš„çœŸå…‡'\n",
    "\n",
    "Support for the HK police (with the phrase/hashtag \"æ’è­¦\", which has come under intense criticisms for its handling of the protests, appear to be more prominent in the rewteets subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DIGGING THROUGH LAYER#3 - THE TOP TROLLS\n",
    "\n",
    "Like in Part 1, I'll sift through the accounts most active in tweeting or retweeting content targetting the HK protest movement. The 10 accounts I picked below are not exhaustive by any means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 SIFTING THROUGH TOP TROLL RETWEETS IN CHINESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trolls_ch = [\n",
    "    \"HKpoliticalnew\",\n",
    "    \"charikamci\",\n",
    "    \"ctcc507\",\n",
    "    \"KondratevFortu\",\n",
    "    \"jdhdnchsdh\",\n",
    "    \"shaunta58sh\",\n",
    "    \"Resilceale\",\n",
    "    \"qujianming1\",\n",
    "    \"vezerullasav158\",\n",
    "    \"ardansuweb\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1817, 21)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting with \"original\" tweets, in Chinese, by the top trolls\n",
    "top_ch_trolls = hk_ch_no_rt[hk_ch_no_rt['user_screen_name'].isin(trolls_ch)]\n",
    "top_ch_trolls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ç‰¹ å€          191\n",
       "æ¸¯ ç¨          189\n",
       "æ¢ ä¾‹          189\n",
       "ç«‹æ³• æœƒ         181\n",
       "ç¾ åœ‹          171\n",
       "å å°          160\n",
       "å€ æ”¿åºœ         155\n",
       "ç‰¹ å€ æ”¿åºœ       152\n",
       "é€ƒçŠ¯ æ¢ ä¾‹       140\n",
       "é€ƒçŠ¯ æ¢         140\n",
       "æ°‘æ— é»¨         133\n",
       "æ— é„­          129\n",
       "é¦™æ¸¯ ç‰¹         114\n",
       "å° æ´¾          113\n",
       "å å° æ´¾        113\n",
       "è¡Œ å‹•          112\n",
       "ç¤¾ æœƒ          111\n",
       "ç¸½ éƒ¨          111\n",
       "é¦™æ¸¯ ç‰¹ å€       109\n",
       "å­¸ ç”Ÿ          107\n",
       "å¤– åœ‹          106\n",
       "è¨˜ è€…          106\n",
       "æœƒ è­°          104\n",
       "å‹¢ åŠ›          102\n",
       "ä¸­ åœ‹          102\n",
       "æ’ è­¦           97\n",
       "ç™¼ å±•           97\n",
       "ä¿® è¨‚           95\n",
       "è­° å“¡           95\n",
       "é„­ å¨¥           93\n",
       "æ— é„­ å¨¥         93\n",
       "é¦™æ¸¯ æ°‘æ—         91\n",
       "å¤§ å­¸           91\n",
       "é™³ æµ©           89\n",
       "å…§ åœ°           89\n",
       "åœ‹ å®¶           86\n",
       "ä½” ä¸­           86\n",
       "é¦™æ¸¯ æ°‘æ— é»¨       86\n",
       "ä¿® ä¾‹           83\n",
       "é™³ æµ© å¤©         81\n",
       "æµ© å¤©           81\n",
       "è‰² é©å‘½          80\n",
       "é•· å®˜           80\n",
       "è¡Œæ”¿ é•· å®˜        80\n",
       "è¡Œæ”¿ é•·          80\n",
       "é¡ è‰²           76\n",
       "é¡ è‰² é©å‘½        75\n",
       "è­¦ ç¸½           74\n",
       "æ´» å‹•           74\n",
       "é¦™æ¸¯ ç‰¹ å€ æ”¿åºœ     72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = top_ch_trolls[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))\n",
    "    \n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list5 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list5.sort_values(ascending = False).head(50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"toptrolls_tweets.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_ch_trolls[top_ch_trolls[\"tweet_text\"].str.contains('ç‰¹å€')].values\n",
    "# top_ch_trolls[top_ch_trolls[\"tweet_text\"].str.contains('æ¸¯ç¨')].values\n",
    "# top_ch_trolls[top_ch_trolls[\"tweet_text\"].str.contains('ç¾åœ‹')].values\n",
    "# top_ch_trolls[top_ch_trolls[\"tweet_text\"].str.contains('é¡è‰²é©å‘½')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUICK TAKE:\n",
    "The top trolls are far more aggressive in pushing the conspiracy theories about the US and other \"hostile foreign forces\" being behind the HK protests. \n",
    "\n",
    "@HKpoliticalnew tweeted on July 1 2019, for instance, that the staff at the UK Consulate in HK, some whom it accused of being \"CIA\" agents, were behind efforts to destablise Hong Kong. On June 13, the same account also sent out a tweet alleging that foreign intelligence agents were working undercover as journalists in order to disrupt the work of the police.\n",
    "\n",
    "Another user, @KondratevFortu alleged that Apple Daily founder Jimmy Lai had flown to the US to conspire with the US to \"interfere\" with Hong Kong's affairs. The tweet was sent on the same day where the [Chinese foreign ministry slammed Mr Lai and top US officials](https://www.scmp.com/news/hong-kong/politics/article/3017868/beijing-foreign-office-slams-hong-kong-tycoon-jimmy-lai-and) for interfering in HK and China's \"internal affairs\".\n",
    "\n",
    "A sample of the tweets below. Uncomment the cell above to see the tweets in full:\n",
    "\n",
    "- @HKpoliticalnew; tweeting at 2019-06-18 16:38:00+08:00: ç¾åœ‹è³‡åŠ©ã€Œæ¸¯ç¨ã€å»¢é’æ´—è…¦\\n#è«œå½±é‡é‡ #é¡è‰²é©å‘½ #é¦™æ¸¯ https://t.co/qZvsZQpwoa'\n",
    "\n",
    "- @HKpoliticalnew; tweeting at 2019-07-01 05:12:00+08:00: 'ç¾åœ‹é¦™æ¸¯é ˜ä½¿é¤¨åƒäººå“¡å·¥ï¼Œä¸å°æ˜¯CIAç‰¹å·¥é€£åŒé¦™æ¸¯æ¼¢å¥¸åœ¨æ¸¯æ¨å‹•é¡è‰²é©å‘½ Over 1,000 US Consulate staffs, many with CIA launched Color Revolution to destabilize HK é¦™æ¸¯è­¦å¯Ÿã€Œé˜¿siræˆ‘æ’ä½ ã€ æ”¯æŒè€…é€¼çˆ†æ·»é¦¬ã€‚\\n\\nå¤šåè—äººè—è¡£æ’è­¦ è­šè© éºŸï¼šå®¶å’Œè¬äº‹èˆˆã€‚\\n\\n#é¦™æ¸¯ #æ’è­¦è¡Œå‹• https://t.co/alO0lhkMc6']\n",
    "\n",
    "\n",
    "- @HKpoliticalnew, tweeting at 2019-06-22 22:16:00+08:00: ç¾åœ‹å–ºé¦™æ¸¯æ¨å‹•é¡è‰²é©å‘½ ç¸½æŒ‡æ®åšŸè‡ªé¦™æ¸¯ç¾åœ‹é ˜äº‹é¤¨ ä¸‹ä»¤ä¸€å®šè¦åˆ¶é€ æµè¡€äº‹ä»¶ ç¾åœ‹è¦è¦‹è¡€è®“å…¶åª’ç¨±...\n",
    "\n",
    "\n",
    "- @HKpoliticalnew; tweeting at 2019-06-13 23:38:00+08:00: 'æ·±æ‰’å…§å¹•ç‰¹å·¥æ‰®æ¼”è¨˜è€…å‚³åª’å…¶å¯¦æ˜¯æš—åœ°è£¡æ“”ä»»æš´äº‚æŒ‡æ®å·¥ä½œæœ‰æ™‚æ•…æ„æ‰®æ¡è¨ªæ‹æ”è€Œæ“‹åœ¨æš´å¾’å‰é¢é˜»ç¤™è­¦å¯Ÿå·¥ä½œåŸ·å‹¤åé€ä¸­ç¾å ´å¤–åœ‹ç‰¹å·¥æŒ‡æ®æš´äº‚é¡è‰²é©å‘½é¦™æ¸¯æ™‚æ”¿ç›´æ“Š'\n",
    "\n",
    "- @KondratevFortu, tweeting at 2019-07-09 14:38:00+08:00 'æœ‰ã€Œä½”ä¸­é»‘æ‰‹ã€ä¹‹ç¨±çš„é¦™æ¸¯å£¹å‚³åª’å‰µè¾¦äººé»æ™ºè‹±èµ´ç¾å‹¾é€£å¤–åœ‹å‹¢åŠ›å¹²é é¦™æ¸¯äº‹å‹™ã€‚ç¾åœ‹åœ‹å‹™é™¢ç™¼è¨€äººå¥§å¡”æ ¼æ–¯ï¼ˆMorgan Ortagusï¼‰å‘¨ä¸€ï¼ˆ8æ—¥ï¼‰ç™¼æ–°èç¨¿ï¼Œè¡¨ç¤ºç¾åœ‹åœ‹å‹™å¿è“¬ä½©å¥§ï¼Œç•¶æ—¥æ–¼é¦–éƒ½è¯ç››é “èˆ‡é»æ™ºè‹±æœƒæ™¤ï¼Œè¨è«–æœ‰é—œé¦™æ¸¯ä¿®è¨‚ã€Šé€ƒçŠ¯æ¢ä¾‹ã€‹çš„ç™¼å±•ï¼Œä»¥åŠé¦™æ¸¯åœ¨ã€Œä¸€åœ‹å…©åˆ¶ã€æ¡†æ¶ä¸‹çš„è‡ªæ²»åœ°ä½ç­‰å•é¡Œã€‚ https://t.co/gHSxwgP1Xa'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SIFTING THROUGH TOP TROLL RETWEETS IN CHINESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 21)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the subset for retweets, in Chinese, by the top trolls\n",
    "top_ch_trolls_rt = hk_ch_rt[hk_ch_rt['user_screen_name'].isin(trolls_ch)]\n",
    "top_ch_trolls_rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "æ’ è­¦         57\n",
       "é¦™æ¸¯ è­¦å¯Ÿ       47\n",
       "ç¤¾ æœƒ         37\n",
       "è¡Œ å‹•         34\n",
       "é¦™æ¸¯ æ’        33\n",
       "æˆ‘ å“‹         30\n",
       "è¡Œ ç‚º         29\n",
       "ç«‹æ³• æœƒ        27\n",
       "è­¦å¯Ÿ å˜…        26\n",
       "å å°         25\n",
       "å° æ´¾         24\n",
       "å å° æ´¾       24\n",
       "è­¦ è¡Œ å‹•       24\n",
       "è­¦ è¡Œ         24\n",
       "æ’ è­¦ è¡Œ       24\n",
       "æ’ è­¦ è¡Œ å‹•     24\n",
       "é¦™æ¸¯ æ’ è­¦      23\n",
       "é¦™æ¸¯ æ’ è­¦ è¡Œ    23\n",
       "åš´ æ­£         23\n",
       "è­´ è²¬         23\n",
       "åŸ· æ³•         22\n",
       "å“‹ éœ€è¦ ä½       20\n",
       "è­¦ éšŠ         20\n",
       "è­¦ éšŠ ä½        20\n",
       "è­¦ éšŠ ä½  æˆ‘     20\n",
       "å“‹ éœ€è¦        20\n",
       "æ’ è­¦ éšŠ ä½      20\n",
       "å­¸ ç”Ÿ         20\n",
       "æ’ è­¦ éšŠ       20\n",
       "éœ€è¦ ä½         20\n",
       "æˆ‘ åŒè¡Œ        20\n",
       "ä½  æˆ‘ åŒè¡Œ      20\n",
       "éšŠ ä½  æˆ‘ åŒè¡Œ    20\n",
       "éšŠ ä½  æˆ‘       20\n",
       "éšŠ ä½          20\n",
       "ä½  æˆ‘         20\n",
       "æˆ‘ å“‹ éœ€è¦      20\n",
       "æˆ‘ å“‹ éœ€è¦ ä½     20\n",
       "é€ƒçŠ¯ æ¡ä¾‹       16\n",
       "ç©© å®š         16\n",
       "æš´åŠ› å˜…        16\n",
       "ç ´ å£         16\n",
       "é¦™æ¸¯ è­¦å¯Ÿ å˜…     16\n",
       "æ­£ åŸ· æ³•       14\n",
       "ç¤¾ æœƒ æ²»å®‰      14\n",
       "åš´ æ­£ åŸ· æ³•     14\n",
       "æœƒ æ²»å®‰        14\n",
       "é€£ çºŒ         14\n",
       "åš´ æ­£ åŸ·       14\n",
       "æ­£ åŸ·         14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = top_ch_trolls_rt[\"clean_tweet_text\"].values\n",
    "text_list = []\n",
    "for t in text:\n",
    "    text_list.append(' '.join(jieba.cut(t, HMM=False)))\n",
    "    \n",
    "vect = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(), stop_words=jb_stopwords, min_df=10, ngram_range=(2, 4)\n",
    ")\n",
    "docs_ch = vect.fit_transform(text_list)\n",
    "features_ch = vect.get_feature_names()\n",
    "\n",
    "count_list6 = pd.DataFrame(docs_ch.toarray(),\n",
    "                       columns=features_ch).sum(axis=0)\n",
    "count_list6.sort_values(ascending = False).head(50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"toptrolls_retweets.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_ch_trolls_rt[top_ch_trolls_rt[\"tweet_text\"].str.contains('åš´æ­£')].values\n",
    "# top_ch_trolls_rt[top_ch_trolls_rt[\"tweet_text\"].str.contains('æ’è­¦è¡Œå‹•')].values\n",
    "# top_ch_trolls_rt[top_ch_trolls_rt[\"tweet_text\"].str.contains('ç¤¾æœƒæ²»å®‰')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retweets continued the earlier trend of showing support for the HK police. This came frequently via the retweets of one of the top troll accounts @HKpoliticalnew. Uncomment the cell above for fuller details. A sample of the tweets:\n",
    "\n",
    "- 'RT @HKpoliticalnew: ã€Œæˆ‘å“‹éœ€è¦ä½ ã€ã€1ã€‘\\n\\né€£æ—¥åšŸå¤šå€‹åœ˜é«”å–ºä¸­ç’°é®æ‰“èŠ±åœ’ç­‰åœ°èˆ‰è¾¦æ’è­¦æ™šæœƒã€è¡—ç«™ï¼Œç²¾åŠ›æ›´æœ‰å¤§æ‰¹äººå“¡åˆ°è­¦ç¸½é«˜å‘¼ã€Œæˆ‘å“‹éœ€è¦ä½ ã€ï¼Œå¤§å«ã€Œæ”¯æŒè­¦å¯Ÿï¼Œåš´æ­£åŸ·æ³•ï¼Œæ„›é¦™æ¸¯ï¼Œæ’è­¦å¯Ÿã€å˜…å£è™Ÿã€‚\\n#é¦™æ¸¯ #æ’è­¦è¡Œå‹• https://t.co/1gp6JqhumY'\n",
    "\n",
    "- 'RT @HKpoliticalnew: æš´å¾’å€‘é€£çºŒæ€§å˜…å»è¡—åš´é‡ç ´å£äº†é¦™æ¸¯ç¤¾æœƒæ²»å®‰ç§©åºï¼Œæ¯†æ‰“åŸ·å‹¤è­¦å“¡â€¦\\n7æœˆ1æ—¥æš´å¾’å€‘æ›´ç³»å¤§è‚†ä½¿ç”¨æš´åŠ›ï¼Œè‚†æ„æ²–æ“Šç ´å£ç«‹æ³•æœƒå¤§æ¨“ï¼Œè€Œåå°æ´¾è­°å“¡éä½†æœªé˜»æ­¢ç¤ºå¨è€…æ­¦åŠ›å‡ç´šï¼Œæ›´å«è­¦å“¡ã€Œå…‹åˆ¶ã€ï¼Œä»²ç‚ºæš´å¾’æä¾›äººåŠ›åŠç‰©è³‡ï¼Œç…½é¢¨é»ç«â€¦\\nå‘¢ç¨®æ™‚å€™åªèƒ½å†€è­¦æ–¹åš´æ­£åŸ·æ³•ï¼Œâ€¦',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 4, I'll use the Scattertext tool to produce interactive visualisations of the English troll tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
